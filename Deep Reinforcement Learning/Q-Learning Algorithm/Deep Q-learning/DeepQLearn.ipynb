{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW8-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnxPx-5rr9gO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def randPair(s,e):\n",
        "    return np.random.randint(s,e), p.random.randint(s,e)\n",
        "\n",
        "#finds an array in the \"depth\" dimension of the grid\n",
        "def findLoc(state, obj):\n",
        "    for i in range(0,5):\n",
        "        for j in range(0,5):\n",
        "            if (state[i,j] == obj).all():\n",
        "                return i,j\n",
        "def initGrid():\n",
        "    state = np.zeros((5,5,5))\n",
        "    #place player\n",
        "    state[0,0] = np.array([0,0,0,0,1])\n",
        "    state[4,4] = np.array([1,0,0,0,0])\n",
        "    \n",
        "    return state\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_Kb_EyAv9eZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def makeMove(state, action):\n",
        "    #need to locate player in grid\n",
        "    #need to determine what object (if any) is in the new grid spot the player is moving to\n",
        "    player_loc = findLoc(state, np.array([0,0,0,0,1]))\n",
        "    goal = findLoc(state, np.array([1,0,0,0,0]))\n",
        "    state = np.zeros((5,5,5))\n",
        "\n",
        "    actions = [[-1,0],[1,0],[0,-1],[0,1]]\n",
        "    #e.g. up => (player row - 1, player column + 0)\n",
        "    new_loc = (player_loc[0] + actions[action][0], player_loc[1] + actions[action][1])\n",
        "    # if (new_loc != wall):\n",
        "    if ((np.array(new_loc) <= (4,4)).all() and (np.array(new_loc) >= (0,0)).all()):\n",
        "        state[new_loc][4] = 1\n",
        "\n",
        "    new_player_loc = findLoc(state, np.array([0,0,0,0,1]))\n",
        "    if (not new_player_loc):\n",
        "        state[player_loc] = np.array([0,0,0,0,1])\n",
        "    state[goal][0] = 1\n",
        "\n",
        "    return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLlckdRwwDkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getLoc(state, level):\n",
        "    for i in range(0,5):\n",
        "        for j in range(0,5):\n",
        "            if (state[i,j][level] == 1):\n",
        "                return i,j\n",
        "\n",
        "def getReward(state):\n",
        "    player_loc = getLoc(state, 4)\n",
        "    pit = getLoc(state, 1)\n",
        "    goal = getLoc(state, 0)\n",
        "    if (player_loc == pit):\n",
        "        return -10\n",
        "    elif (player_loc == goal):\n",
        "        return 10\n",
        "    else:\n",
        "        return -1\n",
        "    \n",
        "def dispGrid(state):\n",
        "    grid = np.zeros((5,5), dtype='str')\n",
        "    player_loc = findLoc(state, np.array([0,0,0,0,1]))\n",
        "    goal = findLoc(state, np.array([1,0,0,0,0]))\n",
        "    for i in range(0,5):\n",
        "        for j in range(0,5):\n",
        "            grid[i,j] = ' '\n",
        "            \n",
        "    if player_loc:\n",
        "        grid[player_loc] = 'S' #player\n",
        "    if goal:\n",
        "        grid[goal] = 'E' #goal\n",
        "    \n",
        "    return grid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUGEc7bwwI4c",
        "colab_type": "code",
        "outputId": "66ac15e4-3f77-4702-f3e6-84bf36d08692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.optimizers import RMSprop"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu9R_-6YwMIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(164, kernel_initializer='lecun_uniform', input_shape=(125,)))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(32, kernel_initializer='lecun_uniform'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(8, kernel_initializer='lecun_uniform'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(16, kernel_initializer='lecun_uniform'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(4, kernel_initializer='lecun_uniform'))\n",
        "model.add(Activation('linear')) #linear output so we can have range of real-valued outputs\n",
        "\n",
        "rms = RMSprop()\n",
        "model.compile(loss='mse', optimizer=rms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuM9sKSXwOhx",
        "colab_type": "code",
        "outputId": "e69b591b-fbae-467a-c233-de760ee204be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import random\n",
        "\n",
        "epochs = 300\n",
        "gamma = 0.9 #since it may take several moves to goal, making gamma high\n",
        "epsilon = 1\n",
        "for i in range(epochs):\n",
        "    \n",
        "    state = initGrid()\n",
        "    status = 1\n",
        "    #while game still in progress\n",
        "    while(status == 1):\n",
        "        #We are in state S\n",
        "        #Let's run our Q function on S to get Q values for all possible actions\n",
        "        qval = model.predict(state.reshape(1,125), batch_size=1)\n",
        "        if (random.random() < epsilon): #choose random action\n",
        "            action = np.random.randint(0,4)\n",
        "        else: #choose best action from Q(s,a) values\n",
        "            action = (np.argmax(qval))\n",
        "        new_state = makeMove(state, action)\n",
        "        reward = getReward(new_state)\n",
        "        newQ = model.predict(new_state.reshape(1,125), batch_size=1)\n",
        "        maxQ = np.max(newQ)\n",
        "        y = np.zeros((1,4))\n",
        "        y[:] = qval[:]\n",
        "        if reward == -1: #non-terminal state\n",
        "            update = (reward + (gamma * maxQ))\n",
        "        else: #terminal state\n",
        "            update = reward\n",
        "        y[0][action] = update #target output\n",
        "        print(\"Game #: %s\" % (i,))\n",
        "        model.fit(state.reshape(1,125), y, batch_size=1, nb_epoch=1, verbose=1)\n",
        "        state = new_state\n",
        "        if reward != -1:\n",
        "            status = 0\n",
        "        clear_output(wait=True)\n",
        "    if epsilon > 0.1:\n",
        "        epsilon -= (1/epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Game #: 299\n",
            "Epoch 1/1\n",
            "\r1/1 [==============================] - 0s 4ms/step - loss: 0.0447\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4N7Xr83wUXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testAlgo(init=0):\n",
        "    i = 0\n",
        "    if init==0:\n",
        "        state = initGrid()\n",
        "    elif init==1:\n",
        "        state = initGridPlayer()\n",
        "    elif init==2:\n",
        "        state = initGridRand()\n",
        "\n",
        "    print(\"Initial State:\")\n",
        "    print(dispGrid(state))\n",
        "    status = 1\n",
        "    #while game still in progress\n",
        "    while(status == 1):\n",
        "        qval = model.predict(state.reshape(1,125), batch_size=1)\n",
        "        action = (np.argmax(qval)) #take action with highest Q-value\n",
        "        print('Move #: %s; Taking action: %s' % (i, action))\n",
        "        state = makeMove(state, action)\n",
        "        print(dispGrid(state))\n",
        "        reward = getReward(state)\n",
        "        if reward!=-1 :\n",
        "            status = 0\n",
        "            print(\"Reward: %s\" % (reward,))\n",
        "        i += 1 #If we're taking more than 10 actions, just stop, we probably can't win this game\n",
        "        if (i > 20):\n",
        "            print(\"Game lost; too many moves.\")\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quHrOs-XwZDK",
        "colab_type": "code",
        "outputId": "67c11e23-bb59-48e0-9089-c64a953627be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        }
      },
      "source": [
        "testAlgo(init=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial State:\n",
            "[['S' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' 'E']]\n",
            "Move #: 0; Taking action: 3\n",
            "[[' ' 'S' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' 'E']]\n",
            "Move #: 1; Taking action: 3\n",
            "[[' ' ' ' 'S' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' 'E']]\n",
            "Move #: 2; Taking action: 1\n",
            "[[' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' 'S' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' 'E']]\n",
            "Move #: 3; Taking action: 3\n",
            "[[' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' 'S' ' ']\n",
            " [' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' 'E']]\n",
            "Move #: 4; Taking action: 3\n",
            "[[' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' 'S']\n",
            " [' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' 'E']]\n",
            "Move #: 5; Taking action: 1\n",
            "[[' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' 'S']\n",
            " [' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' 'E']]\n",
            "Move #: 6; Taking action: 1\n",
            "[[' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' 'S']\n",
            " [' ' ' ' ' ' ' ' 'E']]\n",
            "Move #: 7; Taking action: 1\n",
            "[[' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' ' ']\n",
            " [' ' ' ' ' ' ' ' ' ']]\n",
            "Reward: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTxK7TRzwbDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGg3z2KaL36V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}